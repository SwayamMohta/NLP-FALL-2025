{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# NLP Class Activity 3: Stemming vs. Lemmatization\n",
        "\n",
        "### **Objective**\n",
        "This notebook demonstrates and compares two fundamental text normalization techniques in Natural Language Processing (NLP): **Stemming** and **Lemmatization**.\n",
        "\n",
        "The goal of both is to reduce a word to its root form, but they do so in very different ways.\n",
        "* **Stemming** is a crude, rule-based process that chops off the end of words. It's fast but sometimes the result isn't a real word. (Think of it as a quick, messy haircut ).\n",
        "* **Lemmatization** is a more sophisticated, dictionary-based process that returns the actual base form of a word, known as the lemma. (Think of this as a smart dictionary lookup ).\n"
      ],
      "metadata": {
        "id": "--2T_60q-TfW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Step 1: Setup and Initialization**\n",
        "* The code begins by importing the necessary tools from the **NLTK** (Natural Language Toolkit) library:\n",
        "    * `PorterStemmer`:  algorithm for stemming.\n",
        "    * `WordNetLemmatizer`: tool that uses the WordNet dictionary to find word lemmas.\n",
        "\n",
        "### **Step 2: The Main Loop and Processing**\n",
        "* The code iterates through a predefined `list` of words.\n",
        "* For each `word` in the list, it performs two actions:\n",
        "    1.  **Stemming**: It calls `stemmer.stem(word)` to get the stemmed form.\n",
        "    2.  **Lemmatization**: It calls `lemmatizer.lemmatize(word)`.\n",
        "\n",
        "### **Step 3: Displaying Results**\n",
        "* After processing each word, the original word, its stemmed version, and its lemmatized version are printed in a neatly formatted table."
      ],
      "metadata": {
        "id": "obqZW0bW-YWs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Dh_VXbexTyg"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.stem import WordNetLemmatizer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "id": "VXc7c_wnxcx3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stemmer = PorterStemmer()\n",
        "lemmatizer = WordNetLemmatizer()"
      ],
      "metadata": {
        "id": "RuVk9y2Mxgx7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words = ['running', 'painting', 'walking', 'dressing', 'likely', 'children', 'whom', 'good', 'ate', 'fishing']"
      ],
      "metadata": {
        "id": "jDFsipruxijb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"{'Original Word':<15} | {'Stemmed Word':<15} | {'Lemmatized Word (Lemma)':<20}\")\n",
        "print(\"-\" * 60)\n",
        "\n",
        "for word in words:\n",
        "    stemmed_word = stemmer.stem(word)\n",
        "\n",
        "    if word.endswith('ing') or word == 'ate':\n",
        "        lemmatized_word = lemmatizer.lemmatize(word, pos='v')\n",
        "    else:\n",
        "        lemmatized_word = lemmatizer.lemmatize(word)\n",
        "    print(f\"{word:<15} | {stemmed_word:<15} | {lemmatized_word:<20}\")"
      ],
      "metadata": {
        "id": "rRJ_xjFxxkhH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}